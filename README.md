## Course Topics

This course covers a wide range of topics, each essential for understanding and effectively utilizing parallel computing:

1. **Moore's Law and Multicore**: Understanding the limitations of Moore's Law and the transition to multicore processors.

2. **Multicore Programming using OpenMP**: Learning how to write parallel programs for multicore processors using OpenMP.

3. **Speedups and Amdahl's Law**: Studying the theoretical limits of parallelization as described by Amdahl's Law and practical speedup techniques.

4. **Hyperthreading**: Exploring hyperthreading technology and its impact on parallel program performance.

5. **Caching Issues and False Sharing**: Identifying and addressing caching issues and false sharing to optimize parallel program performance.

6. **Data Decomposition**: Techniques for breaking down data into parallelizable chunks.

7. **Functional Decomposition**: Methods for dividing program functions to run in parallel.

8. **Single Instruction Multiple Data (SIMD)**: Utilizing SIMD for parallel processing at the instruction level.

9. **GPU Computing**: Leveraging Graphics Processing Units (GPUs) for general-purpose computing using:
   - **CUDA**: NVIDIA's parallel computing platform and programming model.
   - **OpenCL**: Open standard for cross-platform, parallel programming.

10. **OpenCL / OpenGL Interoperability**: Combining OpenCL with OpenGL for advanced graphics and compute applications.

11. **Message Passing Interface (MPI)**: Programming with MPI to enable communication between processes in parallel computing environments.

